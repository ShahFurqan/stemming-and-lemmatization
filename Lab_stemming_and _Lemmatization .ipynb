{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e50ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Pakistan is the 33rd-largest country by area, spanning 881,913 square kilometres (340,509 square miles). It has a 1,046-kilometre (650-mile) coastline along the Arabian Sea and Gulf of Oman in the south, and is bordered by India to the east, Afghanistan to the west, Iran to the southwest, and China to the northeast.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e896313",
   "metadata": {},
   "source": [
    "# fisrt perfom tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5056469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pakistan', 'is', 'the', '33rd-largest', 'country', 'by', 'area', ',', 'spanning', '881,913', 'square', 'kilometres', '(', '340,509', 'square', 'miles', ')', '.', 'It', 'has', 'a', '1,046-kilometre', '(', '650-mile', ')', 'coastline', 'along', 'the', 'Arabian', 'Sea', 'and', 'Gulf', 'of', 'Oman', 'in', 'the', 'south', ',', 'and', 'is', 'bordered', 'by', 'India', 'to', 'the', 'east', ',', 'Afghanistan', 'to', 'the', 'west', ',', 'Iran', 'to', 'the', 'southwest', ',', 'and', 'China', 'to', 'the', 'northeast', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "sent=word_tokenize(sentence)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5005a",
   "metadata": {},
   "source": [
    "# Remove the punchuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc28bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pakistan', 'is', 'the', '33rd-largest', 'country', 'by', 'area', ',', 'spanning', '881,913', 'square', 'kilometres', '(', '340,509', 'square', 'miles', ')', '.', 'It', 'has', 'a', '1,046-kilometre', '(', '650-mile', ')', 'coastline', 'along', 'the', 'Arabian', 'Sea', 'and', 'Gulf', 'of', 'Oman', 'in', 'the', 'south', ',', 'and', 'is', 'bordered', 'by', 'India', 'to', 'the', 'east', ',', 'Afghanistan', 'to', 'the', 'west', ',', 'Iran', 'to', 'the', 'southwest', ',', 'and', 'China', 'to', 'the', 'northeast', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "def remove_punct(token):\n",
    "    return [word for word in token if word.isalpha()]\n",
    "snet =remove_punct(sent)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c17f53",
   "metadata": {},
   "source": [
    "# stemming for english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5df013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', 'is', 'the', '33rd-largest', 'countri', 'by', 'area', ',', 'span', '881,913', 'squar', 'kilometr', '(', '340,509', 'squar', 'mile', ')', '.', 'it', 'ha', 'a', '1,046-kilometr', '(', '650-mile', ')', 'coastlin', 'along', 'the', 'arabian', 'sea', 'and', 'gulf', 'of', 'oman', 'in', 'the', 'south', ',', 'and', 'is', 'border', 'by', 'india', 'to', 'the', 'east', ',', 'afghanistan', 'to', 'the', 'west', ',', 'iran', 'to', 'the', 'southwest', ',', 'and', 'china', 'to', 'the', 'northeast', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps= PorterStemmer()\n",
    "ps_stem_set=[ps.stem(word) for word in sent ]\n",
    "print(ps_stem_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad3756",
   "metadata": {},
   "source": [
    "# Snowball Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb4b18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', 'is', 'the', '33rd-largest', 'countri', 'by', 'area', ',', 'span', '881,913', 'squar', 'kilometr', '(', '340,509', 'squar', 'mile', ')', '.', 'it', 'has', 'a', '1,046-kilometr', '(', '650-mile', ')', 'coastlin', 'along', 'the', 'arabian', 'sea', 'and', 'gulf', 'of', 'oman', 'in', 'the', 'south', ',', 'and', 'is', 'border', 'by', 'india', 'to', 'the', 'east', ',', 'afghanistan', 'to', 'the', 'west', ',', 'iran', 'to', 'the', 'southwest', ',', 'and', 'china', 'to', 'the', 'northeast', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sb=SnowballStemmer('english')\n",
    "sb_stem_sent=[sb.stem(word) for word in sent]\n",
    "print(sb_stem_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdfff3",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f272ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pakistan', 'is', 'the', '33rd-largest', 'country', 'by', 'area', ',', 'spanning', '881,913', 'square', 'kilometre', '(', '340,509', 'square', 'mile', ')', '.', 'It', 'ha', 'a', '1,046-kilometre', '(', '650-mile', ')', 'coastline', 'along', 'the', 'Arabian', 'Sea', 'and', 'Gulf', 'of', 'Oman', 'in', 'the', 'south', ',', 'and', 'is', 'bordered', 'by', 'India', 'to', 'the', 'east', ',', 'Afghanistan', 'to', 'the', 'west', ',', 'Iran', 'to', 'the', 'southwest', ',', 'and', 'China', 'to', 'the', 'northeast', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download ('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "lem_sent=[lemmatizer.lemmatize(word) for word in sent]\n",
    "print(lem_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefefc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
